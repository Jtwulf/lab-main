検定について
----

**前提条件**

周波数に関する実験にて，各セクションのデータについて有意差がないことを示したい．

* Experiment1: 各セクションの周波数特徴量の平均値についての実験
    点群データ→ 4(intro,drop,break,outro)
* Experiment2: パート別の各セクションの周波数特徴量の平均値についての実験
    点群データ→ 4*4=16(drums(intro,drop,break,outro),bass(intro,,,),,,,)

サンプルサイズ: 195
これは一般的な基準では大きいと言えるぽい

**検定の手順**

1. **データの正規性の検討**
    * 各セクションの点群データが正規分布かを判定
        → パラメトリック検定はデータが正規分布に従うことを前提としている為
    * 正規分布ではない場合，非パラメトリック検定を検討
    * 手法: シャピロ・ウィルク検定 etc.

2. **等分散性の検討**
    * グループ間で分散が等しいか評価
        → これもパラメトリック検定の前提条件の一つ
    * 手法: レヴィンの検定，バートレットの検定

3. **パラメトリック検定or非パラメトリック検定**
    * 1. 2.の結果を評価して，どの検定手法を用いるか決定する
    * グループ間の平均値に有意な違いがあるかを評価
    * p値について
        * p値が統計的に重要な閾値（通常は0.05）より小さい場合，グループ間に統計的に有意な差があると考えられる
        * p値が閾値より大きい場合，有意な差がないと考えられる（ただし，実際には差があっても検出できない「第二種の過誤」の可能性も考慮する必要あり）
        * 「有意差がある」の反対は「有意差があるとは言えない」である点を留意する．

4. **事後検定**
    * 検定の結果，p値が閾値を上回り有意な結果が得られた場合，どのセクション間に違いがあるのかを特定する
    * 多重比較は事後検定のこと
    * 手法: ツケーのHSD検定、ボンフェローニ補正

**pythonで実装出来るもの**

* 正規性の検討
    * シャピロ・ウィルク検定：
        * `scipy.stats`モジュールの`shapiro`関数
        * 小さなサンプルサイズ（通常は5000サンプル未満）での正規性を検定するのに適している
    * ダゴスティーノのK^2検定：
        * `scipy.stats`モジュールの`normaltest`関数
        * サンプルサイズが大きい場合に推奨される
    * アンダーソン・ダーリング検定：
        * `scipy.stats`モジュールの`anderson`関数
        * より厳密な正規性検定が必要な場合に使用される

* 等分散性の検討
    * レヴェンの検定：
        * `scipy.stats`モジュールの`levene`関数
        * グループ間での分散が等しいかどうかを検定する
    * バートレットの検定：
        * `scipy.stats`モジュールの`bartlett`関数
        * サンプルが正規分布に従っているときに推奨される
    * ブラウン-フォーサイス検定：
        * `scipy.stats`モジュールの`fligner`または`levene`関数を使用し，`levene`の場合は中央値を中心とした検定を行う
        * 正規分布を仮定しない等分散性検定

* パラメトリック検定

**選択手法**

* データの正規性：ダゴスティーノのK^2検定
* データの等分散性：レヴィンの検定

**結果(データの正規性，データの等分散性)**

Normality test for intro: Statistics = 21.949779128951832, p-value = 1.7126397616977218e-05
Normality test for drop: Statistics = 2.821290793972529, p-value = 0.24398576465072427
Normality test for break: Statistics = 0.025021684488967133, p-value = 0.9875670929919688
Normality test for outro: Statistics = 32.03135056110743, p-value = 1.1078490808232814e-07
Levene's test for homoscedasticity: Statistics = 41.14565669666013, p-value = 1.2188188360901619e-24

**評価**

* データの正規性
    * イントロとアウトロはp値が非常に小さいので，正規分布に従ってない
    * ドロップとブレイクは正規分布に従っている
    * 非パラメトリック検定を使うか，データの変換(対数変換など)を行うか

* データの等分散性
    * p値が非常に小さいため，異なるセクション間のデータの分散は等しくない．まあ正規性の結果からこれは自明
    * →等分散性を前提とするパラメトリック検定(ANOVAなど)は適してない
    * なので，検定の方法は次の3択になる

* データを変換した上でのパラメトリック検定
    * 正規性がないデータに対して，対数変換や平方根変換などを行って正規分布に近づけることができる場合は，パラメトリック検定が使える
    * データ変換（対数変換）を行なった結果
        Reevaluated normality test for intro: Statistics = 6.77703334129838, p-value = 0.03375871507176448
        Reevaluated normality test for drop: Statistics = 12.219343234183503, p-value = 0.00222128012347214
        Reevaluated normality test for break: Statistics = 23.83692835909924, p-value = 6.666175974917747e-06
        Reevaluated normality test for outro: Statistics = 47.15310321788657, p-value = 5.7654569535665786e-11
        更に正規分布から外れてしまったので，多分データ変換してパラメトリック検定を使う方針はやめた方がいい

* ウェルチのANOVA検定([https://zenn.dev/tmizuho/articles/648c7f37869914](https://zenn.dev/tmizuho/articles/648c7f37869914))
    * 等分散性を仮定しないANOVAの形式で，異なるセクション間の平均の違いを検定できる　← ただ，正規性を前提とするからきつい

* 非パラメトリック検定
    * クラスカル・ウォリス検定：ANOVAの非パラメトリックな代替手法として、異なるセクション間での中央値の違いを検定するのに適している ← 今回は4つ(16つ)のデータを比較するので，これ一択
    * マン・ホイットニーU検定：二つの独立したサンプル群間の中央値の差を検定するために使用される
    * ウィルコクソンの符号順位検定：二つの対応のあるサンプルのグループ間での違いを検定します。対応のあるt検定の非パラメトリックな代替手法です。

**選択手法**

* 非パラメトリック検定：クラスカル・ウォリス検定(平均値ではなく中央値についての比較である点に留意)

**検定結果**

Kruskal-Wallis test: Statistics = 70.71760398337165, p-value = 2.996313371181593e-15

**評価**

p値が非常に小さいので，少なくとも一つのセクションが異なるセクションの中央値と有意差がある

詳しくは事後検定を行う．

**事後検定について**

* 目的
    * 複数のグループの比較で有意差がある場合，どのグループ間で有意差があるのか明らかにする
* 手法
    * ツケーのHSD（Honestly Significant Difference）検定：
        * ANOVAの後に使われる
    * ボンフェローニ補正：
        * 複数の比較を行う際に用いられる
    * ダンの多重比較検定：
        * クラスカル・ウォリス検定の後に使われる　← これを採用
        * 多重比較の問題を考慮した手法らしい
        * pythonでの実装:[https://www.geeksforgeeks.org/how-to-perform-dunns-test-in-python/](https://www.geeksforgeeks.org/how-to-perform-dunns-test-in-python/)
        * 参考:[https://qiita.com/rola_satoru/items/af2bcad7826672891f80](https://qiita.com/rola_satoru/items/af2bcad7826672891f80)
    * シェフェの手法：
        * 保守的らしい

**選択手法**

* 事後検定：ダンの多重比較検定

**事後検定結果**

Dunn's test results (p-values):

|       | break           | drop            | intro           | outro           |
|-------|-----------------|-----------------|-----------------|-----------------|
| break | 1.000000e+00    | 0.033925        | 3.378913e-09    | 1.707324e-13    |
| drop  | 0.033925        | 1.000000        | 0.002914        | 5.754806e-06    |
| intro | 3.378913e-09    | 0.002914        | 1.000000e+00    | 9.867979e-01    |
| outro | 1.707324e-13    | 0.000006        | 9.867979e-01    | 1.000000e+00    |


**評価**

* **ブレイク vs ドロップ**：p値 = 0.033925
    * 有意差あり
* **ブレイク vs イントロ**：p値 ≈ 3.38e-09
    * 強い有意差あり
* **ブレイク vs アウトロ**：p値 ≈ 1.71e-13
    * 強い有意差あり
* **ドロップ vs イントロ**：p値 = 0.002914
    * 有意差あり
* **ドロップ vs アウトロ**：p値 ≈ 5.75e-06
    * 強い有意差あり
* **イントロ vs アウトロ**：p値 ≈ 0.986798
    * 有意差な
* イントロとアウトロの組み合わせ以外はSpectral Centroidのデータに有意差がある

**結論**

正規性，等分散性ともに無かったので非パラメトリック検定を利用．その結果，p値が閾より高く，異なるセクションで有意差があることが分かった．事後検定では，イントロとアウトロの組み合わせ以外に有意差があることが分かった．
よって，有意差が無いという記述は適切ではない．
